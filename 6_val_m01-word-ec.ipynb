{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62834c84-8927-4023-b24c-67e5db655b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input:\n",
    "test_speaker = \"M01\"\n",
    "split=\"val\"\n",
    "level = 'word'\n",
    "pattern = \"keep_all\"\n",
    "\n",
    "ngram_order = 3\n",
    "target_lang=\"en\"\n",
    "text_count_threshold = 40\n",
    "model_user = \"macarious\"\n",
    "model_repo = f\"torgo_xlsr_finetune_{test_speaker}\"\n",
    "model_repo_path = f\"{model_user}/{model_repo}\"\n",
    "\n",
    "kenlm_model_user = \"macarious\"\n",
    "kenlm_model_repo = f\"europarl_bilingual_kenlm_{ngram_order}-gram\"\n",
    "kenlm_model_repo_path= f\"{kenlm_model_user}/{kenlm_model_repo}\"\n",
    "\n",
    "if ngram_order == 1:\n",
    "  kenlm_model = \"\"\n",
    "else:\n",
    "  kenlm_model = f\"{ngram_order}gram.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95301722-8580-4dff-aafa-971d8d0e75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n",
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/google/colab/data_table.py:30: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils import traitlets as _traitlets\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from huggingface_hub import Repository\n",
    "from datasets import load_dataset, DatasetDict, Dataset, Audio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2ProcessorWithLM\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dc4366-b87d-4c6c-b31a-15d43b621e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download the trained model\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_repo_path)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a6efd7-be1a-4e10-ada8-ac29877f2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_local_path = f\"kenlm_model_{ngram_order}gram_words_europarl\"\n",
    "# lm_repo = Repository(local_dir=lm_local_path, clone_from=kenlm_model_repo_path)\n",
    "# lm_repo.git_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d4d5f5-d61d-488d-8e78-a81ef67ad86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers: F01, F03, F04, FC01, FC02, FC03, M01, M02, M03, M04, M05, MC01, MC02, MC03, MC04\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "data_df = pd.read_csv('torgo.csv')\n",
    "dataset_csv = load_dataset('csv', data_files='torgo.csv')\n",
    "\n",
    "speakers = data_df['speaker_id'].unique()\n",
    "\n",
    "print(f'Speakers: {\", \".join(speakers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b05a87-5299-44c8-9b91-9537c9add497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 14580\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 1075\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 739\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train, valid, test sets\n",
    "valid_speaker = 'F03' if test_speaker != 'F03' else 'F04'\n",
    "train_speaker = [s for s in speakers if s not in [test_speaker, valid_speaker]]\n",
    "\n",
    "torgo_dataset = DatasetDict()\n",
    "torgo_dataset['train'] = dataset_csv['train'].filter(lambda x: x in train_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['validation'] = dataset_csv['train'].filter(lambda x: x == valid_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['test'] = dataset_csv['train'].filter(lambda x: x == test_speaker, input_columns=['speaker_id'])\n",
    "\n",
    "torgo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d27846d-fe48-41a2-9cc9-4e1a7391e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times the text has been spoken in each of the 'train',\n",
    "# 'validation', and 'test' sets. Remove text according to the\n",
    "# text_count_threshold from a previous cell.\n",
    "\n",
    "if pattern == \"no_keep\":\n",
    "    unique_texts = set(torgo_dataset['train'].unique(column='text')) | set(torgo_dataset['validation'].unique(column='text')) | set(torgo_dataset['test'].unique(column='text'))\n",
    "    unique_texts_count = {}\n",
    "    \n",
    "    for text in unique_texts:\n",
    "      unique_texts_count[text] = {'train_validation': 0, 'test': 0}\n",
    "    \n",
    "    for text in torgo_dataset['train']['text']:\n",
    "      unique_texts_count[text]['train_validation'] += 1\n",
    "    \n",
    "    for text in torgo_dataset['validation']['text']:\n",
    "      unique_texts_count[text]['train_validation'] += 1\n",
    "    \n",
    "    for text in torgo_dataset['test']['text']:\n",
    "      unique_texts_count[text]['test'] += 1\n",
    "    \n",
    "    texts_to_keep_in_train_validation = []\n",
    "    texts_to_keep_in_test = []\n",
    "    for text in unique_texts_count:\n",
    "      if unique_texts_count[text]['train_validation'] < text_count_threshold and unique_texts_count[text]['test'] > 0:\n",
    "        texts_to_keep_in_test.append(text)\n",
    "      else:\n",
    "        texts_to_keep_in_train_validation.append(text)\n",
    "    \n",
    "    original_data_count = {'train': len(torgo_dataset['train']), 'validation': len(torgo_dataset['validation']), 'test': len(torgo_dataset['test'])}\n",
    "    \n",
    "    # Update the three dataset splits\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].filter(lambda x: x['text'] in texts_to_keep_in_train_validation)\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].filter(lambda x: x['text'] in texts_to_keep_in_train_validation)\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].filter(lambda x: x['text'] in texts_to_keep_in_test)\n",
    "    \n",
    "    print(f'Train:       {len(torgo_dataset[\"train\"])}/{original_data_count[\"train\"]} ({len(torgo_dataset[\"train\"]) * 100 // original_data_count[\"train\"]}%)')\n",
    "    print(f'Validation:  {len(torgo_dataset[\"validation\"])}/{original_data_count[\"validation\"]} ({len(torgo_dataset[\"validation\"]) * 100 // original_data_count[\"validation\"]}%)')\n",
    "    print(f'Test:        {len(torgo_dataset[\"test\"])}/{original_data_count[\"test\"]} ({len(torgo_dataset[\"test\"]) * 100 // original_data_count[\"test\"]}%)')\n",
    "    \n",
    "    print()\n",
    "    torgo_dataset\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080b972f-4068-4bdc-9bab-1237f068bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to process data:\n",
    "\n",
    "# Remove special characters and convert all text into lowercase\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"0-9]'\n",
    "sampling_rate=16000\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch['text'] = re.sub(chars_to_ignore_regex, ' ', batch['text']).lower()\n",
    "    return batch\n",
    "\n",
    "def prepare_torgo_dataset(batch):\n",
    "    # Load audio data into batch\n",
    "    audio = batch['audio']\n",
    "\n",
    "    # Extract values\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "\n",
    "    # Encode to label ids\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec366ed8-8336-4d49-bebc-d27a00f01cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91633bd15ea4248aa176fdbc842e542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SystemError",
     "evalue": "initialization of _internal failed without raising an exception",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/utils/py_utils.py\", line 625, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 3458, in _map_single\n    example = apply_function_on_filtered_inputs(example, i, offset=offset)\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 3361, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n  File \"/tmp/ipykernel_46252/528616043.py\", line 13, in prepare_torgo_dataset\n    audio = batch['audio']\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 272, in __getitem__\n    value = self.format(key)\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 370, in format\n    return self.formatter.format_column(self.pa_table.select([key]))[0]\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 442, in format_column\n    column = self.python_features_decoder.decode_column(column, pa_table.column_names[0])\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 218, in decode_column\n    return self.features.decode_column(column, column_name) if self.features else column\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/features/features.py\", line 1961, in decode_column\n    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/features/features.py\", line 1961, in <listcomp>\n    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/features/features.py\", line 1340, in decode_nested_example\n    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id)\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/features/audio.py\", line 153, in decode_example\n    import librosa\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/librosa/__init__.py\", line 209, in <module>\n    from . import core\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/librosa/core/__init__.py\", line 5, in <module>\n    from .convert import *  # pylint: disable=wildcard-import\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/librosa/core/convert.py\", line 7, in <module>\n    from . import notation\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/librosa/core/notation.py\", line 8, in <module>\n    from ..util.exceptions import ParameterError\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/librosa/util/__init__.py\", line 77, in <module>\n    from .utils import *  # pylint: disable=wildcard-import\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/librosa/util/utils.py\", line 9, in <module>\n    import numba\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/numba/__init__.py\", line 42, in <module>\n    from numba.np.ufunc import (vectorize, guvectorize, threading_layer,\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/numba/np/ufunc/__init__.py\", line 3, in <module>\n    from numba.np.ufunc.decorators import Vectorize, GUVectorize, vectorize, guvectorize\n  File \"/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/numba/np/ufunc/decorators.py\", line 3, in <module>\n    from numba.np.ufunc import _internal\nSystemError: initialization of _internal failed without raising an exception\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Filter audio within a certain length\u001b[39;00m\n\u001b[1;32m     20\u001b[0m torgo_test_set \u001b[38;5;241m=\u001b[39m torgo_test_set\u001b[38;5;241m.\u001b[39mcast_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m, Audio(sampling_rate\u001b[38;5;241m=\u001b[39msampling_rate))\n\u001b[0;32m---> 21\u001b[0m torgo_test_set \u001b[38;5;241m=\u001b[39m \u001b[43mtorgo_test_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprepare_torgo_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m  \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msession\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspeaker_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m  \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m min_input_length_in_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     27\u001b[0m max_input_length_in_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    556\u001b[0m }\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3197\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3191\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3193\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3194\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3195\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3196\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3197\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   3198\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[1;32m   3199\u001b[0m     ):\n\u001b[1;32m   3200\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3201\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/utils/py_utils.py:665\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    664\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m         [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/datasets/utils/py_utils.py:665\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    664\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/multiprocess/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mSystemError\u001b[0m: initialization of _internal failed without raising an exception"
     ]
    }
   ],
   "source": [
    "torgo_test_set = torgo_dataset['validation']\n",
    "'''\n",
    "  ******************** For debugging ********************\n",
    "'''\n",
    "# torgo_test_set = torgo_test_set.select(range(50))\n",
    "'''\n",
    "  ******************** For debugging ********************\n",
    "'''\n",
    "\n",
    "# Remove special characters\n",
    "torgo_test_set = torgo_test_set.map(remove_special_characters)\n",
    "\n",
    "\n",
    "if level == 'sentence':\n",
    "    torgo_test_set = torgo_test_set.filter(lambda example: len(example[\"text\"].split()) > 1)\n",
    "else:\n",
    "    torgo_test_set = torgo_test_set.filter(lambda example: len(example[\"text\"].split()) == 1)\n",
    "\n",
    "# Filter audio within a certain length\n",
    "torgo_test_set = torgo_test_set.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "torgo_test_set = torgo_test_set.map(\n",
    "  prepare_torgo_dataset,\n",
    "  remove_columns=['session', 'audio', 'speaker_id'],\n",
    "  num_proc=4)\n",
    "\n",
    "min_input_length_in_sec = 1.0\n",
    "max_input_length_in_sec = 10.0\n",
    "torgo_test_set = torgo_test_set.filter(lambda x: x < max_input_length_in_sec * sampling_rate, input_columns=[\"input_length\"])\n",
    "torgo_test_set = torgo_test_set.filter(lambda x: x > min_input_length_in_sec * sampling_rate, input_columns=[\"input_length\"])\n",
    "\n",
    "print()\n",
    "torgo_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d9277-a704-472b-98b2-d55e302fc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(processor, model, dataset, lm_model_path=None):\n",
    "\n",
    "  predictions = []\n",
    "  references = []\n",
    "\n",
    "  if not lm_model_path:\n",
    "    for i in tqdm(range(dataset.num_rows)):\n",
    "      inputs = processor(dataset[i][\"input_values\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "      with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "      predicted_ids = torch.argmax(logits, dim=-1)\n",
    "      transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "      predictions.append(transcription[0].lower())\n",
    "      references.append(dataset[i][\"text\"])\n",
    "\n",
    "  else:\n",
    "    vocab_dict = processor.tokenizer.get_vocab()\n",
    "    sorted_vocab_dict = {k: v for k, v in sorted(\n",
    "        vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "    unigrams = set()\n",
    "\n",
    "    with open(f\"{lm_local_path}/unigrams.txt\", \"r\") as f:\n",
    "      for line in f:\n",
    "        line = line.strip()\n",
    "        unigrams.add(line)\n",
    "\n",
    "    # Implement language model in the decoder\n",
    "    decoder = build_ctcdecoder(\n",
    "        labels=list(sorted_vocab_dict.keys()),\n",
    "        kenlm_model_path=lm_model_path if ngram_order > 1 else None,\n",
    "        unigrams=unigrams\n",
    "    )\n",
    "\n",
    "    # Build new processor with new decoder\n",
    "    processor = Wav2Vec2ProcessorWithLM(\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        decoder=decoder\n",
    "    )\n",
    "\n",
    "    # Transcripe the audio\n",
    "    for i in tqdm(range(dataset.num_rows)):\n",
    "      inputs = processor(dataset[i][\"input_values\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "      with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "      transcription = processor.batch_decode(logits.numpy()).text\n",
    "\n",
    "      predictions.append(transcription[0].lower())\n",
    "      references.append(dataset[i][\"text\"])\n",
    "\n",
    "  # Calculate the wer score\n",
    "  wer = load(\"wer\")\n",
    "  wer_score = wer.compute(predictions=predictions, references=references)\n",
    "\n",
    "  return wer_score, predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346d576-3ec1-4089-b4b6-a33a4dcc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_score_no_lm, predictions_no_lm, references_no_lm = evaluateModel(processor, model, torgo_test_set)\n",
    "\n",
    "print(f\"WER (no LM): {wer_score_no_lm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135cbbe-9132-4d8d-afb7-14c45be12c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_score_lm, predictions_lm, references_lm = evaluateModel(processor, model, torgo_test_set, f\"{lm_local_path}/{kenlm_model}\")\n",
    "\n",
    "print(f\"WER ({ngram_order}-gram): {wer_score_lm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f535880-eae6-4c50-a978-aa3622c22ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = set()\n",
    "\n",
    "with open(f\"{lm_local_path}/unigrams.txt\", \"r\") as f:\n",
    "  for line in f:\n",
    "    line = line.strip()\n",
    "    unigrams.add(line)\n",
    "\n",
    "print(len(set(\"\".join(unigrams))))\n",
    "print(set(\"\".join(unigrams)))\n",
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53a8d4-4308-4290-88a8-9da46ad91475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Save results to a csv file\n",
    "with open(f\"results_{ngram_order}gram_{test_speaker}_{test_speaker}_{level}_{pattern}_{split}.txt\", \"w\") as csv_file:\n",
    "  csv_writer = csv.writer(csv_file)\n",
    "  csv_writer.writerow([\"Prediction (no LM)\", f\"Prediction ({ngram_order}-gram)\", \"Reference\"])\n",
    "  for i in range(len(predictions_no_lm)):\n",
    "    csv_writer.writerow([predictions_no_lm[i], predictions_lm[i], references_lm[i]])\n",
    "\n",
    "# Display as dataframe\n",
    "results_df = pd.read_csv(f\"results_{ngram_order}gram_{test_speaker}_{test_speaker}_{level}_{pattern}_{split}.txt\")\n",
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2104de4-e6d9-4e7b-84cf-51725becba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wer to a csv file\n",
    "\n",
    "with open(f\"wer_{ngram_order}gram_{test_speaker}_{test_speaker}_{level}_{pattern}_{split}.txt\", \"w\") as csv_file:\n",
    "  csv_writer = csv.writer(csv_file)\n",
    "  csv_writer.writerow([\"Language Model\", \"WER\"])\n",
    "  csv_writer.writerow([\"None\", wer_score_no_lm])\n",
    "  csv_writer.writerow([f\"{ngram_order}-gram\", wer_score_lm])\n",
    "\n",
    "# Display as dataframe\n",
    "results_wer_df = pd.read_csv(f\"wer_{ngram_order}gram_{test_speaker}_{test_speaker}_{level}_{pattern}_{split}.txt\")\n",
    "results_wer_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9aca74-3dea-4037-b0eb-76d09643c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string of current date\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Zip the results into a single file for download\n",
    "output_zip_path = f\"results_with_LM_{test_speaker}_{test_speaker}_{level}_{pattern}_{split}_{current_date}.zip\"\n",
    "with zipfile.ZipFile(output_zip_path, \"w\") as zip_file:\n",
    "  zip_file.write(f\"results_{ngram_order}gram_{test_speaker}_{test_speaker}_{level}_{pattern}_{split}.txt\")\n",
    "  zip_file.write(f\"wer_{ngram_order}gram_{test_speaker}_{test_speaker}_{level}_{pattern}_{split}.txt\")\n",
    "\n",
    "files.download(output_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b2e59-7340-4757-9bb2-6c48afd6b58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
