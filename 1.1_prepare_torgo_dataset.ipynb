{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2c0b232a-98b1-4802-8638-52944a6ebb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.0\n"
     ]
    }
   ],
   "source": [
    "%run 00_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fcb5b1d9-2835-40f2-b674-62f9089b326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_keep_all = {}\n",
    "dataframes_no_keep_all = {}\n",
    "\n",
    "for speaker_dir in os.listdir('results'):\n",
    "    if os.path.isdir(os.path.join('results', speaker_dir)) and not speaker_dir.endswith('.ipynb_checkpoints'):\n",
    "        # speaker_dir = speaker_dir.rstrip('_')\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "        valid_df = None\n",
    "\n",
    "        for file in os.listdir(os.path.join('results', speaker_dir)):\n",
    "            if file.endswith('.csv'):\n",
    "                df_name = os.path.splitext(file)[0]\n",
    "                df_path = os.path.join('results', speaker_dir, file)\n",
    "                \n",
    "                if 'train' in df_name:\n",
    "                    if train_df is None:\n",
    "                        train_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'test' in df_name:\n",
    "                    if test_df is None:\n",
    "                        test_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'validation' in df_name:\n",
    "                    if valid_df is None:\n",
    "                        valid_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "        \n",
    "        combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        if 'keep_all' in speaker_dir:\n",
    "            dataframes_keep_all[speaker_dir] = combined_df\n",
    "        else:\n",
    "            dataframes_no_keep_all[speaker_dir] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "180e1843-1000-4e98-92d1-1ba07cd797e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_keep_all = {}\n",
    "dataframes_no_keep_all = {}\n",
    "\n",
    "for speaker_dir in os.listdir('results'):\n",
    "    if os.path.isdir(os.path.join('results', speaker_dir)) and not speaker_dir.endswith('.ipynb_checkpoints'):\n",
    "        # speaker_dir = speaker_dir.rstrip('_')\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "        valid_df = None\n",
    "\n",
    "        for file in os.listdir(os.path.join('results', speaker_dir)):\n",
    "            if file.endswith('.csv'):\n",
    "                df_name = os.path.splitext(file)[0]\n",
    "                df_path = os.path.join('results', speaker_dir, file)\n",
    "                \n",
    "                if 'train' in df_name:\n",
    "                    if train_df is None:\n",
    "                        train_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'test' in df_name:\n",
    "                    if test_df is None:\n",
    "                        test_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'validation' in df_name:\n",
    "                    if valid_df is None:\n",
    "                        valid_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "        \n",
    "        combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        if 'keep_all' in speaker_dir:\n",
    "            dataframes_keep_all[speaker_dir] = combined_df\n",
    "        else:\n",
    "            dataframes_no_keep_all[speaker_dir] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "56941ce1-5050-4bf6-b9cb-72c0c74e3a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_M04 - Data Size: 11751\n",
      "torgo_xlsr_finetune_M02 - Data Size: 9790\n",
      "torgo_xlsr_finetune_F03 - Data Size: 8568\n",
      "torgo_xlsr_finetune_M05 - Data Size: 8853\n",
      "torgo_xlsr_finetune_M03 - Data Size: 9572\n",
      "torgo_xlsr_finetune_F01 - Data Size: 14409\n",
      "torgo_xlsr_finetune_M01 - Data Size: 6540\n",
      "torgo_xlsr_finetune_F04 - Data Size: 9454\n",
      "\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 16082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_dataframe_sizes(dataframes_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "adb2b4bf-d842-49a3-9b7a-81fb1690c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 12115\n",
      "\n",
      "torgo_xlsr_finetune_M04 - Data Size: 9139\n",
      "torgo_xlsr_finetune_M02 - Data Size: 7687\n",
      "torgo_xlsr_finetune_F03 - Data Size: 6813\n",
      "torgo_xlsr_finetune_M05 - Data Size: 7178\n",
      "torgo_xlsr_finetune_M03 - Data Size: 7480\n",
      "torgo_xlsr_finetune_F01 - Data Size: 10795\n",
      "torgo_xlsr_finetune_M01 - Data Size: 4404\n",
      "torgo_xlsr_finetune_F04 - Data Size: 7482\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2601735946.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all = {}\n",
    "dataframes_sentence_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "dataframes_word_no_keep_all = {}\n",
    "dataframes_sentence_no_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_no_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_no_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_no_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "# print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "# print_dataframe_sizes(dataframes_sentence_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41fdcd6b-1eee-49b5-b87f-a926d0fe5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframes(dataframes_dict, col_names):\n",
    "    processed_dataframes = {}\n",
    "\n",
    "    for df_name, df in dataframes_dict.items():\n",
    "        # Remove duplicates and drop NaN values\n",
    "        df = df.drop_duplicates(subset=col_names, keep=False)\n",
    "        df = df.dropna() \n",
    "        processed_dataframes[df_name] = df\n",
    "\n",
    "    return processed_dataframes\n",
    "\n",
    "def convert_to_phonemes(data_frame, remove_num=True):\n",
    "    g2p = G2p()\n",
    "\n",
    "    for df_name, df in data_frame.items():\n",
    "        df['predictions_phoneme'] = df['predictions'].apply(lambda x: \" \".join(g2p(x)).strip())\n",
    "        df['references_phoneme'] = df['references'].apply(lambda x: \" \".join(g2p(x)).strip())\n",
    "\n",
    "        if remove_num:\n",
    "            # Remove numeric values\n",
    "            df['predictions_phoneme'] = df['predictions_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "            df['references_phoneme'] = df['references_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "        df.drop(['predictions', 'references'], axis=1, inplace=True)\n",
    "        # Drop all duplicates based on predictions_phoneme and references_phoneme\n",
    "        df.drop_duplicates(subset=['predictions_phoneme', 'references_phoneme'], keep=False, inplace=True)\n",
    "\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a62a541-dfb2-4d31-b030-b48f0046d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 296\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 534\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 452\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 449\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 328\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 336\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 288\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 399\n",
      "\n",
      "torgo_xlsr_finetune_M04 - Data Size: 432\n",
      "torgo_xlsr_finetune_M02 - Data Size: 405\n",
      "torgo_xlsr_finetune_F03 - Data Size: 356\n",
      "torgo_xlsr_finetune_M05 - Data Size: 404\n",
      "torgo_xlsr_finetune_M03 - Data Size: 285\n",
      "torgo_xlsr_finetune_F01 - Data Size: 305\n",
      "torgo_xlsr_finetune_M01 - Data Size: 352\n",
      "torgo_xlsr_finetune_F04 - Data Size: 340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all = process_dataframes(dataframes_word_keep_all, col_names)\n",
    "# dataframes_sentence_keep_all = process_dataframes(dataframes_sentence_keep_all, col_names)\n",
    "dataframes_word_no_keep_all = process_dataframes(dataframes_word_no_keep_all, col_names)\n",
    "# dataframes_sentence_no_keep_all = process_dataframes(dataframes_sentence_no_keep_all, col_names)\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "# print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "# print_dataframe_sizes(dataframes_sentence_no_keep_all)\n",
    "# dataframes_word_keep_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11263227",
   "metadata": {},
   "source": [
    "# output no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ccbb07a9-a31e-493a-bb35-349b6f3f055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_word_no_keep_all_phoneme = convert_to_phonemes(dataframes_word_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa0c5cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions_phoneme</th>\n",
       "      <th>references_phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>S W IY T</td>\n",
       "      <td>S W IY T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>F AY</td>\n",
       "      <td>F AO R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>EY P</td>\n",
       "      <td>EY T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>HH AA</td>\n",
       "      <td>HH AO L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>T UW</td>\n",
       "      <td>T UW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11742</th>\n",
       "      <td>R EY K</td>\n",
       "      <td>L EY K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11743</th>\n",
       "      <td>T IH P</td>\n",
       "      <td>Z IH P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>N AH S T</td>\n",
       "      <td>N EH S T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11745</th>\n",
       "      <td>R EH JH</td>\n",
       "      <td>R AY D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11748</th>\n",
       "      <td>S AW TH IY S T</td>\n",
       "      <td>S EH L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions_phoneme references_phoneme\n",
       "143              S W IY T           S W IY T\n",
       "170                  F AY             F AO R\n",
       "684                  EY P               EY T\n",
       "1411                HH AA            HH AO L\n",
       "3281                 T UW               T UW\n",
       "...                   ...                ...\n",
       "11742              R EY K             L EY K\n",
       "11743              T IH P             Z IH P\n",
       "11744            N AH S T           N EH S T\n",
       "11745             R EH JH             R AY D\n",
       "11748      S AW TH IY S T             S EH L\n",
       "\n",
       "[412 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_word_no_keep_all_phoneme['torgo_xlsr_finetune_M04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b158f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_M04 - Data Size: 412\n",
      "torgo_xlsr_finetune_M02 - Data Size: 394\n",
      "torgo_xlsr_finetune_F03 - Data Size: 327\n",
      "torgo_xlsr_finetune_M05 - Data Size: 385\n",
      "torgo_xlsr_finetune_M03 - Data Size: 264\n",
      "torgo_xlsr_finetune_F01 - Data Size: 283\n",
      "torgo_xlsr_finetune_M01 - Data Size: 336\n",
      "torgo_xlsr_finetune_F04 - Data Size: 317\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'torgo_xlsr_finetune_M04':       predictions_phoneme references_phoneme\n",
       " 143              S W IY T           S W IY T\n",
       " 170                  F AY             F AO R\n",
       " 684                  EY P               EY T\n",
       " 1411                HH AA            HH AO L\n",
       " 3281                 T UW               T UW\n",
       " ...                   ...                ...\n",
       " 11742              R EY K             L EY K\n",
       " 11743              T IH P             Z IH P\n",
       " 11744            N AH S T           N EH S T\n",
       " 11745             R EH JH             R AY D\n",
       " 11748      S AW TH IY S T             S EH L\n",
       " \n",
       " [412 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M02':      predictions_phoneme references_phoneme\n",
       " 69                S IY T            SH IY T\n",
       " 144             S W IY T           S W IY T\n",
       " 170      F L AO R L AO R             F AO R\n",
       " 516                 EY P               EY T\n",
       " 518             R IH G T             R AY T\n",
       " ...                  ...                ...\n",
       " 9760            G R IY F             L IY K\n",
       " 9764            D AA R S             D AY S\n",
       " 9772             HH IY P              HH IY\n",
       " 9784            N UW S T           N EH S T\n",
       " 9785          R AH JH IY             R AY D\n",
       " \n",
       " [394 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_F03':      predictions_phoneme references_phoneme\n",
       " 493               EY G T               EY T\n",
       " 780                HH AA            HH AO L\n",
       " 1375             EY T IY               EY T\n",
       " 2363               JH IY             G EH S\n",
       " 2364                AH K            OW K EY\n",
       " ...                  ...                ...\n",
       " 8404       F AO R F AW R             F AO R\n",
       " 8413              B IH T             P IH T\n",
       " 8416              B AE T             F AE T\n",
       " 8486   S AY G OW F IH SH               S AY\n",
       " 8490           F UH R UW           F L AO R\n",
       " \n",
       " [327 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M05':      predictions_phoneme references_phoneme\n",
       " 7             S T AO R M         S T AO R M\n",
       " 145             S W IY T           S W IY T\n",
       " 171            F UH R AW             F AO R\n",
       " 292                HH AY            HH IH M\n",
       " 985               P AE T            HH AE T\n",
       " ...                  ...                ...\n",
       " 8830            G R IY K             L IY K\n",
       " 8832              D ER K             D AY S\n",
       " 8838             HH IY P              HH IY\n",
       " 8848              R AH G             R AY D\n",
       " 8850                S OW             S EH L\n",
       " \n",
       " [385 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M03':      predictions_phoneme references_phoneme\n",
       " 150             S W IY T           S W IY T\n",
       " 154                 EY T               EY T\n",
       " 176               F AW R             F AO R\n",
       " 312              HH AH M            HH IH M\n",
       " 933               EY G T               EY T\n",
       " ...                  ...                ...\n",
       " 9545                R IY             L IY K\n",
       " 9546              L EY K             R EH D\n",
       " 9554             SH AY P              HH IY\n",
       " 9565             SH IH P             Z IH P\n",
       " 9567          HH R UW JH             R AY D\n",
       " \n",
       " [264 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_F01':       predictions_phoneme references_phoneme\n",
       " 84               S W IY T           S W IY T\n",
       " 175             F ER F ER             F AO R\n",
       " 581                  IH M            HH IH M\n",
       " 1663               W EY Z           W EY S T\n",
       " 1679                CH EY            HH AO L\n",
       " ...                   ...                ...\n",
       " 14373              L IH K             R EH D\n",
       " 14384             HH IY P              HH IY\n",
       " 14401                IH P             Z IH P\n",
       " 14402            M AH S T           N EH S T\n",
       " 14403             R AY JH             R AY D\n",
       " \n",
       " [283 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M01':      predictions_phoneme references_phoneme\n",
       " 12              S W IY T           S W IY T\n",
       " 2030             OW K EY            OW K EY\n",
       " 2182                  IY             M AY L\n",
       " 2441       R IH L AE K S      R IH L AE K S\n",
       " 2570              L IH S        W IH S K IY\n",
       " ...                  ...                ...\n",
       " 6527             HH AY P              HH IY\n",
       " 6530                F OW               F OW\n",
       " 6536                IH P             Z IH P\n",
       " 6537            M ER S T           N EH S T\n",
       " 6538             R UW JH             R AY D\n",
       " \n",
       " [336 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_F04':      predictions_phoneme references_phoneme\n",
       " 272               EY G T               EY T\n",
       " 275                 EY P               EY T\n",
       " 1506                AE D               AE D\n",
       " 2713            K EH T S             G EH S\n",
       " 2714              G EH S            OW K EY\n",
       " ...                  ...                ...\n",
       " 9429              L EH D             R EH D\n",
       " 9438             HH IH T              HH IY\n",
       " 9443              S AY T             S AY D\n",
       " 9448              R EY K             L EY K\n",
       " 9449              R AH D             R AY D\n",
       " \n",
       " [317 rows x 2 columns]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_dataframe_sizes(dataframes_word_no_keep_all_phoneme)\n",
    "dataframes_word_no_keep_all_phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3208bf47-d0d2-4741-83f5-956b30dbe113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_M04 - Data Size: 412\n",
      "torgo_xlsr_finetune_M02 - Data Size: 394\n",
      "torgo_xlsr_finetune_F03 - Data Size: 327\n",
      "torgo_xlsr_finetune_M05 - Data Size: 385\n",
      "torgo_xlsr_finetune_M03 - Data Size: 264\n",
      "torgo_xlsr_finetune_F01 - Data Size: 283\n",
      "torgo_xlsr_finetune_M01 - Data Size: 336\n",
      "torgo_xlsr_finetune_F04 - Data Size: 317\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M04\n",
      "Word Error Rate (WER): 66.33%\n",
      "Character Error Rate (CER): 52.16%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02\n",
      "Word Error Rate (WER): 68.28%\n",
      "Character Error Rate (CER): 54.30%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03\n",
      "Word Error Rate (WER): 61.68%\n",
      "Character Error Rate (CER): 49.80%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05\n",
      "Word Error Rate (WER): 63.00%\n",
      "Character Error Rate (CER): 50.48%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03\n",
      "Word Error Rate (WER): 53.70%\n",
      "Character Error Rate (CER): 42.24%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F01\n",
      "Word Error Rate (WER): 61.62%\n",
      "Character Error Rate (CER): 48.89%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01\n",
      "Word Error Rate (WER): 55.68%\n",
      "Character Error Rate (CER): 42.22%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04\n",
      "Word Error Rate (WER): 47.35%\n",
      "Character Error Rate (CER): 37.70%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_dataframe_sizes(dataframes_word_no_keep_all_phoneme)\n",
    "def calculate_error_rates(dataframes, phoneme_names=['predictions', 'references']):\n",
    "    for df_name, df in dataframes.items():\n",
    "        references = df[phoneme_names[1]].tolist()\n",
    "        hypotheses = df[phoneme_names[0]].tolist()\n",
    "\n",
    "        wer_score = wer(references, hypotheses)\n",
    "        cer_score = cer(references, hypotheses)\n",
    "\n",
    "        print(f'Speaker: {df_name}')\n",
    "        print(f'Word Error Rate (WER): {wer_score:.2%}')\n",
    "        print(f'Character Error Rate (CER): {cer_score:.2%}')\n",
    "        print()\n",
    "\n",
    "calculate_error_rates(dataframes_word_no_keep_all_phoneme, phoneme_names=['predictions_phoneme', 'references_phoneme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "feae38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORGO_TRAIN_TYPE = TorgoTrainType.WORD_NO_KEEP.value\n",
    "OUT_DIR = f'data/kenlm_{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "# Check if OUT_DIR exists, if not, create it\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc0dc1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def export_to_txt(dataframes_dict, output_directory):\n",
    "#     if not os.path.exists(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "\n",
    "#     for speaker, df in dataframes_dict.items():\n",
    "#         predictions_file_path = os.path.join(output_directory, f'{speaker}_predictions_phoneme.txt')\n",
    "#         references_file_path = os.path.join(output_directory, f'{speaker}_references_phoneme.txt')\n",
    "\n",
    "#         df[['predictions_phoneme']].to_csv(predictions_file_path, index=False, header=False, sep='\\t')\n",
    "#         df[['references_phoneme']].to_csv(references_file_path, index=False, header=False, sep='\\t')\n",
    "\n",
    "# export_to_txt(dataframes_word_no_keep_all_phoneme, OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28446b34-1d32-456d-968e-1efc44fa239d",
   "metadata": {},
   "source": [
    "# output Keep ALL phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "855c583d-b45a-4250-9f31-a5b33e8dad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 279\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 519\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 430\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 420\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 311\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 318\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 280\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 370\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04_keep_all\n",
      "Word Error Rate (WER): 63.20%\n",
      "Character Error Rate (CER): 49.67%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02_keep_all\n",
      "Word Error Rate (WER): 67.02%\n",
      "Character Error Rate (CER): 51.25%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05_keep_all\n",
      "Word Error Rate (WER): 64.46%\n",
      "Character Error Rate (CER): 53.12%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M04__keep_all\n",
      "Word Error Rate (WER): 68.75%\n",
      "Character Error Rate (CER): 54.22%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03_keep_all\n",
      "Word Error Rate (WER): 63.57%\n",
      "Character Error Rate (CER): 50.07%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F01_keep_all\n",
      "Word Error Rate (WER): 64.39%\n",
      "Character Error Rate (CER): 49.83%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03_keep_all\n",
      "Word Error Rate (WER): 64.69%\n",
      "Character Error Rate (CER): 50.59%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01_keep_all\n",
      "Word Error Rate (WER): 61.05%\n",
      "Character Error Rate (CER): 47.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all_phoneme = convert_to_phonemes(dataframes_word_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_keep_all_phoneme)\n",
    "calculate_error_rates(dataframes_word_keep_all_phoneme, phoneme_names=['predictions_phoneme', 'references_phoneme'])\n",
    "\n",
    "TORGO_TRAIN_TYPE = TorgoTrainType.WORD_KEEP.value\n",
    "OUT_DIR = f'data/kenlm_{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "# # Check if OUT_DIR exists, if not, create it\n",
    "# if not os.path.exists(OUT_DIR):\n",
    "#     os.makedirs(OUT_DIR)\n",
    "    \n",
    "# def export_to_txt(dataframes_dict, output_directory):\n",
    "#     if not os.path.exists(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "\n",
    "#     for speaker, df in dataframes_dict.items():\n",
    "#         predictions_file_path = os.path.join(output_directory, f'{speaker}_predictions_phoneme.txt')\n",
    "#         references_file_path = os.path.join(output_directory, f'{speaker}_references_phoneme.txt')\n",
    "\n",
    "#         df[['predictions_phoneme']].to_csv(predictions_file_path, index=False, header=False, sep='\\t')\n",
    "#         df[['references_phoneme']].to_csv(references_file_path, index=False, header=False, sep='\\t')\n",
    "\n",
    "# export_to_txt(dataframes_word_keep_all_phoneme, OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c66f0-fdc3-4361-b375-661fb0c1e117",
   "metadata": {},
   "source": [
    "# PREPARE SUPERVISED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e60320-0766-42e4-9249-216a6c5c1146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
