{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15fda4c-40a8-4cd6-a7f9-fbc53db54da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, Audio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2ProcessorWithLM\n",
    "# from pyctcdecode import build_ctcdecoder\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "#from g2p_en import G2p\n",
    "from g2p import make_g2p\n",
    "from num2words import num2words  # Import num2words from nltk\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from huggingface_hub import Repository\n",
    "from datasets import load_dataset, DatasetDict, Dataset, Audio\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "# from google.colab import files\n",
    "from transformers import Wav2Vec2ProcessorWithLM, Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a949c4b7-05df-4c88-aa53-90367485d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_lang = \"en\"\n",
    "target_lang = \"fr\"\n",
    "username = \"jindaznb\"  # change to your username\n",
    "ngram_order = 3\n",
    "repo_user = \"jindaznb\"\n",
    "repo_name = f\"europarl_bilingual_kenlm_{ngram_order}-gram\"\n",
    "repo_path_remote = f\"{repo_user}/{repo_name}\"\n",
    "repo_path_local = f\"{repo_name}\"\n",
    "\n",
    "normal_speakers = ['MC01', 'MC02', 'MC03', 'MC04','FC01','FC02','FC03']\n",
    "atypical_speakers = ['F01', 'F03', 'F04', 'M01', 'M02', 'M03', 'M04', 'M05']\n",
    "\n",
    "test_speaker = \"M01\"\n",
    "\n",
    "\n",
    "target_lang=\"en\"\n",
    "text_count_threshold = 40\n",
    "model_user = \"jindaznb\"\n",
    "model_repo = f\"torgo_xlsr_finetune_{test_speaker}\"\n",
    "model_repo_path = f\"{model_user}/{model_repo}\"\n",
    "\n",
    "kenlm_model_user = \"jindaznb\"\n",
    "kenlm_model_repo = f\"europarl_bilingual_kenlm_{ngram_order}-gram\"\n",
    "kenlm_model_repo_path= f\"{kenlm_model_user}/{kenlm_model_repo}\"\n",
    "if ngram_order == 1:\n",
    "  kenlm_model = \"\"\n",
    "else:\n",
    "  kenlm_model = f\"{ngram_order}gram.bin\"\n",
    "\n",
    "\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "sampling_rate=16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be09dd-4fa9-4355-8ce8-db1eeea3d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers_to_words(text):\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word.isdigit():\n",
    "            # Convert numbers to words\n",
    "            word = num2words(word)\n",
    "        elif re.match(r'\\d+(st|nd|rd|th)', word):\n",
    "            # Handle ordinal numbers\n",
    "            number_part = re.match(r'\\d+', word).group()\n",
    "            ordinal_suffix = re.search(r'(st|nd|rd|th)', word).group()\n",
    "            word = num2words(number_part, ordinal=True) + ordinal_suffix\n",
    "        words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_punctuation_and_special_characters(text):\n",
    "    # Remove punctuation and special characters\n",
    "    return re.sub(r'[^\\w\\s,-]', '', text)\n",
    "\n",
    "def get_vocabulary_from_arpa(arpa_path):\n",
    "    vocabulary = set()\n",
    "\n",
    "    with open(arpa_path, 'r', encoding='utf-8') as arpa_file:\n",
    "        in_data_section = False\n",
    "\n",
    "        for line in arpa_file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line == '\\\\data\\\\':\n",
    "                in_data_section = True\n",
    "            elif line.startswith('\\\\') and in_data_section:\n",
    "                break  # End of data section\n",
    "            elif not line.startswith('\\\\') and in_data_section:\n",
    "                # Inside the n-gram section, extract vocabulary\n",
    "                parts = line.split()\n",
    "                if len(parts) > 1:\n",
    "                    word = parts[1]\n",
    "                    vocabulary.add(word)\n",
    "\n",
    "    return vocabulary\n",
    "\n",
    "def add_tokens_to_arpa(arpa_path, tokens_to_add, tokens_to_exclude):\n",
    "    with open(arpa_path, 'r', encoding='utf-8') as arpa_file:\n",
    "        arpa_content = arpa_file.readlines()\n",
    "\n",
    "    # Find the index where the unigram section starts\n",
    "    start_index = arpa_content.index('\\\\1-grams:\\n') + 1\n",
    "\n",
    "    # Insert entries for the new tokens excluding the ones to exclude\n",
    "    for token in tokens_to_add:\n",
    "        if token not in tokens_to_exclude:\n",
    "            arpa_content.insert(start_index, f'-99.999 {token} -99.999\\n')\n",
    "\n",
    "    # Write the modified content back to the ARPA file\n",
    "    with open(arpa_path, 'w', encoding='utf-8') as arpa_file:\n",
    "        arpa_file.writelines(arpa_content)\n",
    "\n",
    "# Functions to process data:\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "  batch[\"transcript\"] = re.sub(chars_to_ignore_regex, '', batch[\"transcript\"]).lower() + \" \"\n",
    "  batch[\"transcript\"] = re.sub(chars_to_ignore_regex, '', batch[\"transcript\"]).lower()\n",
    "  return batch\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # batched output is \"un-batched\" to ensure mapping is correct\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "\n",
    "    with processor.as_target_processor():\n",
    "        # batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "        batch[\"labels\"] = batch[\"text\"]\n",
    "        # print(processor(batch[\"text\"]))\n",
    "    return batch\n",
    "\n",
    "\n",
    "def evaluateModel(processor, model, dataset, lm_model_path=None):\n",
    "  predictions = []\n",
    "  references = []\n",
    "\n",
    "  if not lm_model_path:\n",
    "    for i in tqdm(range(dataset.num_rows)):\n",
    "      inputs = processor(dataset[i][\"input_values\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "      with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "      predicted_ids = torch.argmax(logits, dim=-1)\n",
    "      transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "      predictions.append(transcription[0].lower())\n",
    "      references.append(dataset[i][\"transcript\"])\n",
    "\n",
    "  else:\n",
    "    vocab_dict = processor.tokenizer.get_vocab()\n",
    "    sorted_vocab_dict = {k: v for k, v in sorted(\n",
    "        vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "    # Implement language model in the decoder\n",
    "    decoder = build_ctcdecoder(\n",
    "        labels=list(sorted_vocab_dict.keys()),\n",
    "        kenlm_model_path=lm_model_path,\n",
    "    )\n",
    "\n",
    "    # Build new processor with new decoder\n",
    "    processor = Wav2Vec2ProcessorWithLM(\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        decoder=decoder\n",
    "    )\n",
    "\n",
    "    # Transcripe the audio\n",
    "    for i in tqdm(range(dataset.num_rows)):\n",
    "      inputs = processor(dataset[i][\"input_values\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "      with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "      transcription = processor.batch_decode(logits.numpy()).text\n",
    "\n",
    "      predictions.append(transcription[0].lower())\n",
    "      references.append(dataset[i][\"transcript\"])\n",
    "\n",
    "  # Calculate the per score\n",
    "  per = load(\"cer\")\n",
    "  per_score = per.compute(predictions=predictions, references=references)\n",
    "\n",
    "  return per_score, predictions, references\n",
    "\n",
    "\n",
    "\n",
    "def map_to_result(batch):\n",
    "  with torch.no_grad():\n",
    "    input_values = torch.tensor(batch[\"input_values\"], device=\"cuda\").unsqueeze(0)\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "  pred_ids = torch.argmax(logits, dim=-1)\n",
    "  batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n",
    "  batch[\"text\"] = batch[\"labels\"]\n",
    "\n",
    "  return batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
