{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62834c84-8927-4023-b24c-67e5db655b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input:\n",
    "test_speaker = \"M01\"\n",
    "ngram_order = 3\n",
    "target_lang=\"en\"\n",
    "text_count_threshold = 40\n",
    "model_user = \"macarious\"\n",
    "model_repo = f\"torgo_xlsr_finetune_{test_speaker}\"\n",
    "model_repo_path = f\"{model_user}/{model_repo}\"\n",
    "\n",
    "kenlm_model_user = \"macarious\"\n",
    "kenlm_model_repo = f\"europarl_bilingual_kenlm_{ngram_order}-gram\"\n",
    "kenlm_model_repo_path= f\"{kenlm_model_user}/{kenlm_model_repo}\"\n",
    "if ngram_order == 1:\n",
    "  kenlm_model = \"\"\n",
    "else:\n",
    "  kenlm_model = f\"output_model.klm_trigram_raw.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c43d10c-6cf8-44a8-af7e-df1ec1b3bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from huggingface_hub import Repository\n",
    "from datasets import load_dataset, DatasetDict, Dataset, Audio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2ProcessorWithLM\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53dc4366-b87d-4c6c-b31a-15d43b621e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download the trained model\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_repo_path)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a6efd7-be1a-4e10-ada8-ac29877f2057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/macarious/europarl_bilingual_kenlm_3-gram into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b8fb02b33246dbaf1bf42bcaabd6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file 3gram.bin:   0%|          | 3.45k/370M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43437f92e2434b82a6479eeae9db230b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file 3gram.bin:   0%|          | 1.00k/370M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_local_path = f\"kenlm_model_{ngram_order}gram_words_europarl\"\n",
    "lm_repo = Repository(local_dir=lm_local_path, clone_from=kenlm_model_repo_path)\n",
    "lm_repo.git_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d4d5f5-d61d-488d-8e78-a81ef67ad86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers: F01, F03, F04, FC01, FC02, FC03, M01, M02, M03, M04, M05, MC01, MC02, MC03, MC04\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "data_df = pd.read_csv('torgo.csv')\n",
    "dataset_csv = load_dataset('csv', data_files='torgo.csv')\n",
    "\n",
    "speakers = data_df['speaker_id'].unique()\n",
    "\n",
    "print(f'Speakers: {\", \".join(speakers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b05a87-5299-44c8-9b91-9537c9add497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792e784a06164521bd4973b33b96dd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522717aeb1f04ecb973a1e34303e8583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724648294be34cceab4f07dc4946684b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 14580\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 1075\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 739\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train, valid, test sets\n",
    "valid_speaker = 'F03' if test_speaker != 'F03' else 'F04'\n",
    "train_speaker = [s for s in speakers if s not in [test_speaker, valid_speaker]]\n",
    "\n",
    "torgo_dataset = DatasetDict()\n",
    "torgo_dataset['train'] = dataset_csv['train'].filter(lambda x: x in train_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['validation'] = dataset_csv['train'].filter(lambda x: x == valid_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['test'] = dataset_csv['train'].filter(lambda x: x == test_speaker, input_columns=['speaker_id'])\n",
    "\n",
    "torgo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d27846d-fe48-41a2-9cc9-4e1a7391e2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0babb7f60b4102891a4926b6b04918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/14580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304e5d833abb419b80ad44e0e16fa66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a63a953d3a4dcaa55bc8fe9fa8c8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d33c1217b7843b3be893380d8db2719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fed0202d9543138be931a7de9e524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72138cdc60947c8a85d539b08e61093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:       8984/14580 (61%)\n",
      "Validation:  582/1075 (54%)\n",
      "Test:        519/739 (70%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 8984\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 582\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['session', 'audio', 'text', 'speaker_id'],\n",
       "        num_rows: 519\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of times the text has been spoken in each of the 'train',\n",
    "# 'validation', and 'test' sets. Remove text according to the\n",
    "# text_count_threshold from a previous cell.\n",
    "unique_texts = set(torgo_dataset['train'].unique(column='text')) | set(torgo_dataset['validation'].unique(column='text')) | set(torgo_dataset['test'].unique(column='text'))\n",
    "unique_texts_count = {}\n",
    "\n",
    "for text in unique_texts:\n",
    "  unique_texts_count[text] = {'train_validation': 0, 'test': 0}\n",
    "\n",
    "for text in torgo_dataset['train']['text']:\n",
    "  unique_texts_count[text]['train_validation'] += 1\n",
    "\n",
    "for text in torgo_dataset['validation']['text']:\n",
    "  unique_texts_count[text]['train_validation'] += 1\n",
    "\n",
    "for text in torgo_dataset['test']['text']:\n",
    "  unique_texts_count[text]['test'] += 1\n",
    "\n",
    "texts_to_keep_in_train_validation = []\n",
    "texts_to_keep_in_test = []\n",
    "for text in unique_texts_count:\n",
    "  if unique_texts_count[text]['train_validation'] < text_count_threshold and unique_texts_count[text]['test'] > 0:\n",
    "    texts_to_keep_in_test.append(text)\n",
    "  else:\n",
    "    texts_to_keep_in_train_validation.append(text)\n",
    "\n",
    "original_data_count = {'train': len(torgo_dataset['train']), 'validation': len(torgo_dataset['validation']), 'test': len(torgo_dataset['test'])}\n",
    "\n",
    "# Update the three dataset splits\n",
    "torgo_dataset['train'] = torgo_dataset['train'].filter(lambda x: x['text'] in texts_to_keep_in_train_validation)\n",
    "torgo_dataset['validation'] = torgo_dataset['validation'].filter(lambda x: x['text'] in texts_to_keep_in_train_validation)\n",
    "torgo_dataset['test'] = torgo_dataset['test'].filter(lambda x: x['text'] in texts_to_keep_in_test)\n",
    "\n",
    "print(f'Train:       {len(torgo_dataset[\"train\"])}/{original_data_count[\"train\"]} ({len(torgo_dataset[\"train\"]) * 100 // original_data_count[\"train\"]}%)')\n",
    "print(f'Validation:  {len(torgo_dataset[\"validation\"])}/{original_data_count[\"validation\"]} ({len(torgo_dataset[\"validation\"]) * 100 // original_data_count[\"validation\"]}%)')\n",
    "print(f'Test:        {len(torgo_dataset[\"test\"])}/{original_data_count[\"test\"]} ({len(torgo_dataset[\"test\"]) * 100 // original_data_count[\"test\"]}%)')\n",
    "\n",
    "print()\n",
    "torgo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080b972f-4068-4bdc-9bab-1237f068bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to process data:\n",
    "\n",
    "# Remove special characters and convert all text into lowercase\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"0-9]'\n",
    "sampling_rate=16000\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch['text'] = re.sub(chars_to_ignore_regex, ' ', batch['text']).lower()\n",
    "    return batch\n",
    "\n",
    "def prepare_torgo_dataset(batch):\n",
    "    # Load audio data into batch\n",
    "    audio = batch['audio']\n",
    "\n",
    "    # Extract values\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "\n",
    "    # Encode to label ids\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27d9277-a704-472b-98b2-d55e302fc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(processor, model, dataset, lm_model_path=None):\n",
    "\n",
    "  predictions = []\n",
    "  references = []\n",
    "\n",
    "  if not lm_model_path:\n",
    "    for i in tqdm(range(dataset.num_rows)):\n",
    "      inputs = processor(dataset[i][\"input_values\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "      with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "      predicted_ids = torch.argmax(logits, dim=-1)\n",
    "      transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "      predictions.append(transcription[0].lower())\n",
    "      references.append(dataset[i][\"text\"])\n",
    "\n",
    "  else:\n",
    "    vocab_dict = processor.tokenizer.get_vocab()\n",
    "    sorted_vocab_dict = {k: v for k, v in sorted(\n",
    "        vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "    unigrams = set()\n",
    "\n",
    "    with open(f\"{lm_local_path}/unigrams.txt\", \"r\") as f:\n",
    "      for line in f:\n",
    "        line = line.strip()\n",
    "        unigrams.add(line)\n",
    "\n",
    "    # Implement language model in the decoder\n",
    "    decoder = build_ctcdecoder(\n",
    "        labels=list(sorted_vocab_dict.keys()),\n",
    "        kenlm_model_path=lm_model_path if ngram_order > 1 else None,\n",
    "        unigrams=unigrams\n",
    "    )\n",
    "\n",
    "    # Build new processor with new decoder\n",
    "    processor = Wav2Vec2ProcessorWithLM(\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        decoder=decoder\n",
    "    )\n",
    "\n",
    "    # Transcripe the audio\n",
    "    for i in tqdm(range(dataset.num_rows)):\n",
    "      inputs = processor(dataset[i][\"input_values\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "      with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "      transcription = processor.batch_decode(logits.numpy()).text\n",
    "\n",
    "      predictions.append(transcription[0].lower())\n",
    "      references.append(dataset[i][\"text\"])\n",
    "\n",
    "  # Calculate the wer score\n",
    "  wer = load(\"wer\")\n",
    "  wer_score = wer.compute(predictions=predictions, references=references)\n",
    "\n",
    "  return wer_score, predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec366ed8-8336-4d49-bebc-d27a00f01cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25bdf56f74e4936ac9ed99d830676a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3a9d590d1c4524bda8d7f1c3dfdee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77c6ba8c725407ab1368c1cf04d8317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604cb87cca3b412f92a483c390114cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/489 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_values', 'input_length', 'labels'],\n",
       "    num_rows: 489\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torgo_test_set = torgo_dataset['test']\n",
    "'''\n",
    "  ******************** For debugging ********************\n",
    "'''\n",
    "# torgo_test_set = torgo_test_set.select(range(50))\n",
    "'''\n",
    "  ******************** For debugging ********************\n",
    "'''\n",
    "\n",
    "# Remove special characters\n",
    "torgo_test_set = torgo_test_set.map(remove_special_characters)\n",
    "\n",
    "# Filter audio within a certain length\n",
    "torgo_test_set = torgo_test_set.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "torgo_test_set = torgo_test_set.map(\n",
    "  prepare_torgo_dataset,\n",
    "  remove_columns=['session', 'audio', 'speaker_id'],\n",
    "  num_proc=4)\n",
    "\n",
    "min_input_length_in_sec = 1.0\n",
    "max_input_length_in_sec = 10.0\n",
    "torgo_test_set = torgo_test_set.filter(lambda x: x < max_input_length_in_sec * sampling_rate, input_columns=[\"input_length\"])\n",
    "torgo_test_set = torgo_test_set.filter(lambda x: x > min_input_length_in_sec * sampling_rate, input_columns=[\"input_length\"])\n",
    "\n",
    "print()\n",
    "torgo_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1346d576-3ec1-4089-b4b6-a33a4dcc5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [05:19<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER (no LM): 0.8779201205727204\n"
     ]
    }
   ],
   "source": [
    "wer_score_no_lm, predictions_no_lm, references_no_lm = evaluateModel(processor, model, torgo_test_set)\n",
    "\n",
    "print(f\"WER (no LM): {wer_score_no_lm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b135cbbe-9132-4d8d-afb7-14c45be12c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "Unigrams and labels don't seem to agree.\n",
      "Only 45 unigrams passed as vocabulary. Is this small or artificial data?\n",
      "100%|██████████| 489/489 [26:01<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER (3-gram): 0.9140919366993218\n"
     ]
    }
   ],
   "source": [
    "wer_score_lm, predictions_lm, references_lm = evaluateModel(processor, model, torgo_test_set, f\"{lm_local_path}/{kenlm_model}\")\n",
    "\n",
    "print(f\"WER ({ngram_order}-gram): {wer_score_lm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f535880-eae6-4c50-a978-aa3622c22ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "{'/', 'F', 'U', 'V', '_', 'P', 'D', 'S', 'G', 'C', 'B', 'H', 'Z', 'W', 'L', 'R', 'K', 'A', '>', 'M', '<', 's', 'J', 'I', 'N', 'E', 'O', 'Y', ',', 'T'}\n",
      "{'JH', '_T', 'F', 'UH', 'AW', 'AA', 'V', '_', 'CH', 'IH', '_S', 'P', 'D', 'IY', '</s>', 'AH', 'S', 'TH', 'UW', '<s>', 'G', 'EY', 'ZH', 'HH', 'DH', 'B', 'NG', 'AY', 'L', 'W', 'Z', 'R', 'SH', 'K', 'OW', 'EH', 'M', 'N', 'AO', 'AE', 'ER', 'Y', ',', 'T', 'OY'}\n"
     ]
    }
   ],
   "source": [
    "unigrams = set()\n",
    "\n",
    "with open(f\"{lm_local_path}/unigrams.txt\", \"r\") as f:\n",
    "  for line in f:\n",
    "    line = line.strip()\n",
    "    unigrams.add(line)\n",
    "\n",
    "print(len(set(\"\".join(unigrams))))\n",
    "print(set(\"\".join(unigrams)))\n",
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df53a8d4-4308-4290-88a8-9da46ad91475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction (no LM)</th>\n",
       "      <th>Prediction (3-gram)</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>traite</td>\n",
       "      <td>traite</td>\n",
       "      <td>trait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trabel</td>\n",
       "      <td>trabl</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feer</td>\n",
       "      <td>feer</td>\n",
       "      <td>fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dresbuy rig balu niveringwat</td>\n",
       "      <td>dresbuly rigebalnivrin gweate</td>\n",
       "      <td>grandfather likes to be modern in his language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rade</td>\n",
       "      <td>rade</td>\n",
       "      <td>raid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a glib inding the wandor all oure inaatde</td>\n",
       "      <td>aglib indingthe wandor oure aade</td>\n",
       "      <td>except in the winter when the ooze or snow or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a ung floing be clam destin</td>\n",
       "      <td>aungflowing stin</td>\n",
       "      <td>a long flowing beard clings to his chin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feer</td>\n",
       "      <td>feer</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tick</td>\n",
       "      <td>tick</td>\n",
       "      <td>tip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bable</td>\n",
       "      <td>bable</td>\n",
       "      <td>bubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>whohe e is verly ninety ayearolde</td>\n",
       "      <td>whohe e isverly ninety ayearolde</td>\n",
       "      <td>well he is nearly ninety three years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arm</td>\n",
       "      <td>arm</td>\n",
       "      <td>horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i l a rad net</td>\n",
       "      <td>i a rad net</td>\n",
       "      <td>i will lead you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dug</td>\n",
       "      <td>dug</td>\n",
       "      <td>dagger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yet ieing as swiply asaber</td>\n",
       "      <td>yetieingasswily asaber</td>\n",
       "      <td>yet he still thinks as swiftly as ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i can read</td>\n",
       "      <td>i can read</td>\n",
       "      <td>i can read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>duges</td>\n",
       "      <td>duges</td>\n",
       "      <td>jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zable</td>\n",
       "      <td>zable</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bargk</td>\n",
       "      <td>bargk</td>\n",
       "      <td>bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sheer</td>\n",
       "      <td>sheer</td>\n",
       "      <td>share</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Prediction (no LM)  \\\n",
       "0                                      traite   \n",
       "1                                      trabel   \n",
       "2                                        feer   \n",
       "3                dresbuy rig balu niveringwat   \n",
       "4                                        rade   \n",
       "5   a glib inding the wandor all oure inaatde   \n",
       "6                 a ung floing be clam destin   \n",
       "7                                        feer   \n",
       "8                                        tick   \n",
       "9                                       bable   \n",
       "10          whohe e is verly ninety ayearolde   \n",
       "11                                        arm   \n",
       "12                              i l a rad net   \n",
       "13                                        dug   \n",
       "14                 yet ieing as swiply asaber   \n",
       "15                                 i can read   \n",
       "16                                      duges   \n",
       "17                                      zable   \n",
       "18                                      bargk   \n",
       "19                                      sheer   \n",
       "\n",
       "                 Prediction (3-gram)  \\\n",
       "0                             traite   \n",
       "1                              trabl   \n",
       "2                               feer   \n",
       "3      dresbuly rigebalnivrin gweate   \n",
       "4                               rade   \n",
       "5   aglib indingthe wandor oure aade   \n",
       "6                   aungflowing stin   \n",
       "7                               feer   \n",
       "8                               tick   \n",
       "9                              bable   \n",
       "10  whohe e isverly ninety ayearolde   \n",
       "11                               arm   \n",
       "12                       i a rad net   \n",
       "13                               dug   \n",
       "14            yetieingasswily asaber   \n",
       "15                        i can read   \n",
       "16                             duges   \n",
       "17                             zable   \n",
       "18                             bargk   \n",
       "19                             sheer   \n",
       "\n",
       "                                            Reference  \n",
       "0                                               trait  \n",
       "1                                             trouble  \n",
       "2                                                 fee  \n",
       "3      grandfather likes to be modern in his language  \n",
       "4                                                raid  \n",
       "5   except in the winter when the ooze or snow or ...  \n",
       "6             a long flowing beard clings to his chin  \n",
       "7                                                fair  \n",
       "8                                                 tip  \n",
       "9                                              bubble  \n",
       "10           well he is nearly ninety three years old  \n",
       "11                                               horn  \n",
       "12                                    i will lead you  \n",
       "13                                             dagger  \n",
       "14             yet he still thinks as swiftly as ever  \n",
       "15                                         i can read  \n",
       "16                                             jacket  \n",
       "17                                             double  \n",
       "18                                                bug  \n",
       "19                                              share  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Save results to a csv file\n",
    "with open(f\"results_{ngram_order}gram_{test_speaker}.txt\", \"w\") as csv_file:\n",
    "  csv_writer = csv.writer(csv_file)\n",
    "  csv_writer.writerow([\"Prediction (no LM)\", f\"Prediction ({ngram_order}-gram)\", \"Reference\"])\n",
    "  for i in range(len(predictions_no_lm)):\n",
    "    csv_writer.writerow([predictions_no_lm[i], predictions_lm[i], references_lm[i]])\n",
    "\n",
    "# Display as dataframe\n",
    "results_df = pd.read_csv(f\"results_{ngram_order}gram_{test_speaker}.txt\")\n",
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2104de4-e6d9-4e7b-84cf-51725becba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wer to a csv file\n",
    "with open(f\"wer_{ngram_order}gram_{test_speaker}.txt\", \"w\") as csv_file:\n",
    "  csv_writer = csv.writer(csv_file)\n",
    "  csv_writer.writerow([\"Language Model\", \"WER\"])\n",
    "  csv_writer.writerow([\"None\", wer_score_no_lm])\n",
    "  csv_writer.writerow([f\"{ngram_order}-gram\", wer_score_lm])\n",
    "\n",
    "# Display as dataframe\n",
    "results_wer_df = pd.read_csv(f\"wer_{ngram_order}gram_{test_speaker}.txt\")\n",
    "results_wer_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9aca74-3dea-4037-b0eb-76d09643c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string of current date\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Zip the results into a single file for download\n",
    "output_zip_path = f\"results_with_LM_{test_speaker}_{current_date}.zip\"\n",
    "with zipfile.ZipFile(output_zip_path, \"w\") as zip_file:\n",
    "  zip_file.write(f\"results_{ngram_order}gram_{test_speaker}.txt\")\n",
    "  zip_file.write(f\"wer_{ngram_order}gram_{test_speaker}.txt\")\n",
    "\n",
    "files.download(output_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b2e59-7340-4757-9bb2-6c48afd6b58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
